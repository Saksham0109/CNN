{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import optim\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pthflops import count_ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=datasets.FashionMNIST(root=\"data\",train=True,download=True,transform=ToTensor())\n",
    "testing=datasets.FashionMNIST(root=\"data\",train=False,download=True,transform=ToTensor())\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(training,batch_size=64)\n",
    "test_dataloader=DataLoader(testing,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LeNet import *\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NeuralNetwork().to(device)\n",
    "learning_rate=0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model,input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.rand(1,1,28,28).to(device)\n",
    "count_ops(model,inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun=nn.CrossEntropyLoss()\n",
    "optimiser=torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_check(loader,model):\n",
    "    correct=0\n",
    "    total=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in (loader):\n",
    "            x=x.to(device=device)\n",
    "            y=y.to(device=device)\n",
    "            scores=model(x)\n",
    "            scores=nn.functional.softmax(scores,dim=1)\n",
    "            _,predictions=scores.max(1)\n",
    "            correct+=(predictions==y).sum()\n",
    "            total+= predictions.size(0)\n",
    "    return float(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img=img.mean(dim=0)\n",
    "     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg,cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_probs(net, images):\n",
    "    output = model(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [nn.functional.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=SummaryWriter('tensor/LeNet-fashionMNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:32, 28.93it/s]\n",
      "938it [00:32, 28.96it/s][05:28<48:59, 32.66s/it]\n",
      " 11%|â–ˆ         | 11/100 [06:01<48:19, 32.58s/it]"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in tqdm(range(100)):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in tqdm(enumerate(train_dataloader, 0)):\n",
    "        inputs, labels = data\n",
    "        optimiser.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fun(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # every 100 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(train_dataloader) + i)\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(model, inputs, labels),\n",
    "                            global_step=epoch * len(train_dataloader) + i)\n",
    "            writer.add_scalar(\"Accuracy\",accuracy_check(test_dataloader,model),global_step=epoch * len(train_dataloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_check(loader,model):\n",
    "    correct=0\n",
    "    total=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in (loader):\n",
    "            x=x.to(device=device)\n",
    "            y=y.to(device=device)\n",
    "            scores=model(x)\n",
    "            scores=nn.functional.softmax(scores,dim=1)\n",
    "            _,predictions=scores.max(1)\n",
    "            correct+=(predictions==y).sum()\n",
    "            total+= predictions.size(0)\n",
    "    print(float(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_check(train_dataloader,model))\n",
    "print(accuracy_check(test_dataloader,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "PATH = \"model.pt\"\n",
    "LOSS = loss\n",
    "\n",
    "torch.save({\n",
    "            'epoch': EPOCH,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimiser.state_dict(),\n",
    "            'loss': LOSS,\n",
    "            }, PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc1bfebef4bde096bcca5b7212ac51dad80d152ee96bf3e05c42062f71dce39e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
